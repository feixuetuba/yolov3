import torch
ONNX_EXPORT = False
from models import create_grids
import numpy as np

nn = torch.nn
import torch.nn.functional as F

def set_ONNX_flag(flag):
    global ONNX_EXPORT
    ONNX_EXPORT = flag

def get_ONNX_flag():
    global ONNX_EXPORT
    return ONNX_EXPORT

class {0}(nn.Module):
    def __init__(self, training=False, img_size=(608, 608)):
        super({0}, self).__init__()
        self.anchors = torch.Tensor([10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326]).reshape((-1, 2))
        self.archive = "default"
        self.n_classes = 80
        self.n_anchor = 3
        self.nx = 0  # initialize number of x gridpoints
        self.ny = 0  # initialize number of y gridpoints
        self.out_0 = YOLOLayer(self.anchors[[6,7,8]], nc=80, arc="default",  training=training,yolo_index=0, img_size=img_size)
        self.out_1 = YOLOLayer(self.anchors[[3,4,5]], nc=80, arc="default",  training=training,yolo_index=1, img_size=img_size)
        self.out_2 = YOLOLayer(self.anchors[[0,1,2]], nc=80, arc="default",  training=training,yolo_index=2, img_size=img_size)
        self.yolo_layers = [0,1,2]
        self.module_list = [self.out_0, self.out_1, self.out_2]

{1}

    def load_pt(self, tiny_slim_pt):
        dkstatict = torch.load(tiny_slim_pt, map_location="cpu")['model']
        self.load_pt_weights(dkstatict)

    def load_pt_weights(self, dkstatict):
        n_dict = self.state_dict()

        for (i, (k, p)), (j, (k2, p2)) in zip(enumerate(dkstatict.items()), enumerate(n_dict.items())):
            shape = p2.shape
            print(k, "->", k2, p.shape, "->", p2.shape)
            if k.split(".")[-1] != k2.split('.')[-1]:
                print("no matched!")
                exit()

            if len(shape) == 4:
                outc, inc, h , w = shape
                n_dict[k2] = p[:outc, :inc]
            elif len(shape) == 1:
                n_dict[k2] = p[:shape[0]]
        self.load_state_dict(n_dict)

    def forward(self, X):
{2}
        return self.wrap_output((yolo0, yolo1, yolo2), self.training, X.size()[2:])

    def wrap_output(self, outputs, training, img_size):
        o1, o2, o3 = outputs
        outputs= [self.out_0(o1, img_size), self.out_1(o2, img_size), self.out_2(o3, img_size)]
        if training:
            return outputs
        elif ONNX_EXPORT:
            output = torch.cat(outputs, 1)  # cat 3 layers 85 x (507, 2028, 8112) to 85 x 10647
            nc = self.module_list[self.yolo_layers[0]].nc  # number of classes
            return output[5:5 + nc].t(), output[:4].t()  # ONNX scores, boxes
        else:
            io, p = list(zip(*outputs))  # inference output, training output
            return torch.cat(io, 1),p
    def CBL(self, in_channels, out_channels, kernel_size, stride, padding, bn, leaky):
        modules = [
            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=not bn)
        ]
        if bn:
            modules.append(nn.BatchNorm2d(out_channels, momentum=0.1))
        if leaky:
            modules.append( nn.LeakyReLU(0.1, inplace=True))
        return nn.Sequential(*modules)

    def get_yolo_layers(model):
        return [i for i, x in enumerate(model.module_defs) if x['type'] == 'yolo']  # [82, 94, 106] for yolov3

class YOLOLayer(nn.Module):
    def __init__(self, anchors, nc, arc, training, yolo_index, img_size):
        super(YOLOLayer, self).__init__()

        self.anchors = torch.Tensor(anchors)
        self.na = len(anchors)  # number of anchors (3)
        self.nc = nc  # number of classes (80)
        self.nx = 0  # initialize number of x gridpoints
        self.ny = 0  # initialize number of y gridpoints
        self.arc = arc
        self.training = training

        if ONNX_EXPORT:  # grids must be computed in __init__
            stride = [32, 16, 8][yolo_index]  # stride of this layer
            self.nx = int(img_size[1] / stride)  # number x grid points
            self.ny = int(img_size[0] / stride)  # number y grid points
            create_grids(self, img_size, (self.nx, self.ny))


    def forward(self, p, img_size, var=None):
        bs, ny, nx = p.shape[0], p.shape[-2], p.shape[-1]
        if (self.nx, self.ny) != (nx, ny):
            create_grids(self, img_size, (nx, ny), p.device, p.dtype)

        # p.view(bs, 255, 13, 13) -- > (bs, 3, 13, 13, 85)  # (bs, anchors, grid, grid, classes + xywh)
        p = p.view(bs, self.na, self.nc + 5, self.ny, self.nx).permute(0, 1, 3, 4, 2).contiguous()  # prediction

        if self.training:
            return p
        elif ONNX_EXPORT:
            # Constants CAN NOT BE BROADCAST, ensure correct shape!
            ngu = self.ng.repeat((1, self.na * self.nx * self.ny, 1))
            grid_xy = self.grid_xy.repeat((1, self.na, 1, 1, 1)).view((1, -1, 2))
            anchor_wh = self.anchor_wh.repeat((1, 1, self.nx, self.ny, 1)).view((1, -1, 2)) / ngu

            p = p.view(-1, 5 + self.nc)
            xy = torch.sigmoid(p[..., 0:2]) + grid_xy[0]  # x, y
            wh = torch.exp(p[..., 2:4]) * anchor_wh[0]  # width, height
            p_conf = torch.sigmoid(p[:, 4:5])  # Conf
            p_cls = F.softmax(p[:, 5:85], 1) * p_conf  # SSD-like conf
            return torch.cat((xy / ngu[0], wh, p_conf, p_cls), 1).t()
        else:
            # s = 1.5  # scale_xy  (pxy = pxy * s - (s - 1) / 2)
            io = p.clone()  # inference output
            io[..., 0:2] = torch.sigmoid(io[..., 0:2]) + self.grid_xy  # xy
            io[..., 2:4] = torch.exp(io[..., 2:4]) * self.anchor_wh  # wh yolo method
            # io[..., 2:4] = ((torch.sigmoid(io[..., 2:4]) * 2) ** 3) * self.anchor_wh  # wh power method
            io[..., :4] *= self.stride

            if 'default' in self.arc:  # seperate obj and cls
                torch.sigmoid_(io[..., 4:])
            elif 'BCE' in self.arc:  # unified BCE (80 classes)
                torch.sigmoid_(io[..., 5:])
                io[..., 4] = 1
            elif 'CE' in self.arc:  # unified CE (1 background + 80 classes)
                io[..., 4:] = F.softmax(io[..., 4:], dim=4)
                io[..., 4] = 1

            if self.nc == 1:
                io[..., 5] = 1  # single-class model https://github.com/ultralytics/yolov3/issues/235

        # reshape from [1, 3, 13, 13, 85] to [1, 507, 85]
        return io.view(bs, -1, 5 + self.nc), p
